{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PneVDYBHrh4S",
        "outputId": "71ed6284-f3e7-4afd-c400-4744e323fa00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Device configuration (Use GPU if available)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "LEARNING_RATE=0.001\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MOUNTING GOOGLE DRIVE**"
      ],
      "metadata": {
        "id": "ImqkN1MtRMKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2Bjk0pgXlRm",
        "outputId": "2e5c2acd-3ba8-40f2-a8f6-2ace56f3a36e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/datasets/archive.zip /content/"
      ],
      "metadata": {
        "id": "E6awPBE_g17A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UNZIPPING THE DATASET ZIP FILE**"
      ],
      "metadata": {
        "id": "ydY4U8caRSxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/archive.zip"
      ],
      "metadata": {
        "id": "-hkk-ZMMi5g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(\"/content/kagglecatsanddogs_3367a/PetImages/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uVTH6Lli5xU",
        "outputId": "b5f1404e-9d35-453d-8d4e-c20251e131cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dog', 'Cat']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONFIRMING THE NUMBER OF IMAGES OF THESE TWO CLASSES**"
      ],
      "metadata": {
        "id": "2ju1C02VRX5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"/content/kagglecatsanddogs_3367a/PetImages/\"))\n",
        "print(len(os.listdir(\"/content/kagglecatsanddogs_3367a/PetImages/Cat\")))\n",
        "print(len(os.listdir(\"/content/kagglecatsanddogs_3367a/PetImages/Dog\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3od759dBi56L",
        "outputId": "194d32c1-0c0e-4265-819a-bd8e8235daf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dog', 'Cat']\n",
            "12491\n",
            "12470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SPLITTING INTO TRAINING AND VALIDATION DATASET**"
      ],
      "metadata": {
        "id": "EVKugqB1Rh5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, random\n",
        "from PIL import Image\n",
        "\n",
        "SRC_DIR = \"/content/kagglecatsanddogs_3367a/PetImages\"\n",
        "DST_DIR = \"/content/cats_dogs\"\n",
        "\n",
        "SPLIT = 0.8\n",
        "random.seed(42)\n",
        "\n",
        "# Create folders\n",
        "for split in [\"train\", \"val\"]:\n",
        "    for cls in [\"cat\", \"dog\"]:\n",
        "        os.makedirs(f\"{DST_DIR}/{split}/{cls}\", exist_ok=True)\n",
        "\n",
        "def process_class(cls):\n",
        "    src = os.path.join(SRC_DIR, cls.capitalize())\n",
        "    files = os.listdir(src)\n",
        "    random.shuffle(files)\n",
        "    cut = int(len(files) * SPLIT)\n",
        "\n",
        "    def copy(files, split):\n",
        "        for f in files:\n",
        "            src_file = os.path.join(src, f)\n",
        "            dst_file = f\"{DST_DIR}/{split}/{cls}/{f}\"\n",
        "            try:\n",
        "                Image.open(src_file).verify()\n",
        "                shutil.copy(src_file, dst_file)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    copy(files[:cut], \"train\")\n",
        "    copy(files[cut:], \"val\")\n",
        "\n",
        "process_class(\"cat\")\n",
        "process_class(\"dog\")\n",
        "\n",
        "print(\" Train/Validation split created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRv-bvZ4kWzf",
        "outputId": "0c0d8599-f304-4f81-b14e-add16e935ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Train/Validation split created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Train cats:\", len(os.listdir(\"/content/cats_dogs/train/cat\")))\n",
        "print(\"Train dogs:\", len(os.listdir(\"/content/cats_dogs/train/dog\")))\n",
        "print(\"Val cats:\", len(os.listdir(\"/content/cats_dogs/val/cat\")))\n",
        "print(\"Val dogs:\", len(os.listdir(\"/content/cats_dogs/val/dog\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXBV2jfpkbfQ",
        "outputId": "89bce71b-abb2-4d69-da18-4d3cce6a474a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train cats: 9991\n",
            "Train dogs: 9975\n",
            "Val cats: 2499\n",
            "Val dogs: 2494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SUPPRESSES PIL TRUNCATED WARNINGS**"
      ],
      "metadata": {
        "id": "H6-LjU13S0Pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from PIL import ImageFile\n",
        "\n",
        "# Allow loading truncated images\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# Suppress PIL truncated image warnings\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=UserWarning,\n",
        "    module=\"PIL\"\n",
        ")"
      ],
      "metadata": {
        "id": "BYfsp71WSb38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET LOADING**"
      ],
      "metadata": {
        "id": "Lvg_a4y6R1B5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "DATASET = \"catsdogs\"\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# ---------------- DEVICE ----------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ---------------- TRANSFORMS ----------------\n",
        "#for cats vs dog\n",
        "IMG_SIZE = 128\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                         (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                         (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# ---------------- DATASET LOADING ----------------\n",
        "\n",
        "print(\"Loading Cats vs Dogs...\")\n",
        "train_dataset = datasets.ImageFolder(\n",
        "        root=\"/content/cats_dogs/train\",\n",
        "        transform=transform_train\n",
        "    )\n",
        "test_dataset = datasets.ImageFolder(\n",
        "        root=\"/content/cats_dogs/val\",\n",
        "        transform=transform_test\n",
        "    )\n",
        "\n",
        "\n",
        "# ---------------- DATALOADERS ----------------\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# ---------------- INFO ----------------\n",
        "classes = train_dataset.classes\n",
        "print(\"Classes:\", classes)\n",
        "print(\"Train samples:\", len(train_dataset))\n",
        "print(\"Test samples:\", len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi-pheUkksqt",
        "outputId": "3bc4879d-901f-41a3-f9df-775c95e7f58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading Cats vs Dogs...\n",
            "Classes: ['cat', 'dog']\n",
            "Train samples: 19966\n",
            "Test samples: 4993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DEFINING THE CONFIGURABLE CNN ARCHITECTURE**"
      ],
      "metadata": {
        "id": "LiF4YqxeR5Gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConfigurableCNN(nn.Module):\n",
        "    def __init__(self, activation_fn_name='relu', num_classes=2):\n",
        "        super(ConfigurableCNN, self).__init__()\n",
        "\n",
        "        # -------- Activation --------\n",
        "        if activation_fn_name == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation_fn_name == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation_fn_name == 'leaky_relu':\n",
        "            self.activation = nn.LeakyReLU(0.01)\n",
        "\n",
        "        # -------- Convolution Blocks --------\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # KEY FIX: adaptive pooling (input-size agnostic)\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
        "\n",
        "        # -------- Classifier --------\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = self.pool(self.activation(self.bn1(self.conv1(x))))\n",
        "\n",
        "        # Block 2\n",
        "        x = self.pool(self.activation(self.bn2(self.conv2(x))))\n",
        "\n",
        "        # Block 3\n",
        "        x = self.pool(self.activation(self.bn3(self.conv3(x))))\n",
        "\n",
        "        # Ensure fixed feature size\n",
        "        x = self.adaptive_pool(x)\n",
        "\n",
        "        # Safe flatten (preserves batch size)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "        # Classifier\n",
        "        x = self.fc1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "F5N5smMlr-QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INITIALIZATION TECHNIQUES**"
      ],
      "metadata": {
        "id": "Wy9Y0sNvxI-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_weight_init(model, init_type='random'):\n",
        "    def init_weights(m):\n",
        "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "            if init_type == 'xavier':\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "            elif init_type == 'kaiming':\n",
        "                nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "            elif init_type == 'random':\n",
        "                nn.init.normal_(m.weight, mean=0.0, std=0.02) # Simple random normal\n",
        "\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    model.apply(init_weights)"
      ],
      "metadata": {
        "id": "EvJlpnYwwWMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAINING UTILITY FUNCTION**"
      ],
      "metadata": {
        "id": "8gegwqgwxBWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, epochs=5):\n",
        "    model.train()\n",
        "    history = {'loss': [], 'acc': []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_acc = 100 * correct / total\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        history['loss'].append(epoch_loss)\n",
        "        history['acc'].append(epoch_acc)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.2f}%\")\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "EEdLLsNUwdF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUATION UTILITY FUNCTION**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tKxArPxjw7mL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    return acc"
      ],
      "metadata": {
        "id": "34tFP-GBwi5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXPERIMENT CONFIGURATIONS (AROUND 27 DIFFERENT CONFIG)**"
      ],
      "metadata": {
        "id": "USq8bHBYS-N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment Configurations\n",
        "activations = ['relu', 'tanh', 'leaky_relu']\n",
        "initializations = ['xavier', 'kaiming', 'random']\n",
        "optimizers_list = ['sgd', 'adam', 'rmsprop']\n",
        "\n",
        "results = []\n",
        "best_acc = 0\n",
        "best_config = {}\n",
        "best_model_state = None\n",
        "\n",
        "print(\"Starting Experiments...\")\n",
        "\n",
        "# Iterate through all combinations\n",
        "for act in activations:\n",
        "    for init in initializations:\n",
        "        for opt_name in optimizers_list:\n",
        "            print(f\"\\n--- Config: Act={act}, Init={init}, Optim={opt_name} ---\")\n",
        "\n",
        "            # 1. Initialize Model\n",
        "            # model = ConfigurableCNN(activation_fn_name=act, num_classes=10).to(device)\n",
        "            model = ConfigurableCNN(\n",
        "            activation_fn_name=act,\n",
        "            num_classes=NUM_CLASSES).to(device)\n",
        "            # 2. Apply Weight Init\n",
        "            apply_weight_init(model, init_type=init)\n",
        "\n",
        "            # 3. Setup Optimizer\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            if opt_name == 'sgd':\n",
        "                optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "            elif opt_name == 'adam':\n",
        "                optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "            elif opt_name == 'rmsprop':\n",
        "                optimizer = optim.RMSprop(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "            # 4. Train\n",
        "\n",
        "            train_hist = train_model(model, train_loader, criterion, optimizer, epochs=10)\n",
        "\n",
        "            # 5. Evaluate\n",
        "            test_acc = evaluate_model(model, test_loader)\n",
        "            print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "            # Store results\n",
        "            results.append({\n",
        "                'config': f\"{act}_{init}_{opt_name}\",\n",
        "                'acc': test_acc\n",
        "            })\n",
        "\n",
        "            # Check for best model\n",
        "            if test_acc > best_acc:\n",
        "                best_acc = test_acc\n",
        "                best_config = {'act': act, 'init': init, 'opt': opt_name}\n",
        "                best_model_state = model.state_dict()\n",
        "                torch.save(model.state_dict(), \"best_custom_cnn.pth\")\n",
        "\n",
        "print(f\"\\nBest Custom Configuration: {best_config} with Acc: {best_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "Tyq-C9e3xTam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a2aa62-8fa4-43b7-c9a0-f0061bc558d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Experiments...\n",
            "\n",
            "--- Config: Act=relu, Init=xavier, Optim=sgd ---\n",
            "Epoch [1/10], Loss: 0.6137, Acc: 66.96%\n",
            "Epoch [2/10], Loss: 0.5289, Acc: 73.22%\n",
            "Epoch [3/10], Loss: 0.4945, Acc: 76.05%\n",
            "Epoch [4/10], Loss: 0.4610, Acc: 77.87%\n",
            "Epoch [5/10], Loss: 0.4403, Acc: 79.65%\n",
            "Epoch [6/10], Loss: 0.4238, Acc: 80.43%\n",
            "Epoch [7/10], Loss: 0.4109, Acc: 81.05%\n",
            "Epoch [8/10], Loss: 0.3976, Acc: 81.98%\n",
            "Epoch [9/10], Loss: 0.3881, Acc: 82.54%\n",
            "Epoch [10/10], Loss: 0.3796, Acc: 83.22%\n",
            "Test Accuracy: 82.01%\n",
            "\n",
            "--- Config: Act=relu, Init=xavier, Optim=adam ---\n",
            "Epoch [1/10], Loss: 0.6469, Acc: 66.86%\n",
            "Epoch [2/10], Loss: 0.5234, Acc: 74.09%\n",
            "Epoch [3/10], Loss: 0.4695, Acc: 77.74%\n",
            "Epoch [4/10], Loss: 0.4331, Acc: 80.54%\n",
            "Epoch [5/10], Loss: 0.3960, Acc: 82.19%\n",
            "Epoch [6/10], Loss: 0.3769, Acc: 83.67%\n",
            "Epoch [7/10], Loss: 0.3520, Acc: 85.01%\n",
            "Epoch [8/10], Loss: 0.3313, Acc: 85.68%\n",
            "Epoch [9/10], Loss: 0.3167, Acc: 86.61%\n",
            "Epoch [10/10], Loss: 0.2969, Acc: 87.67%\n",
            "Test Accuracy: 87.24%\n",
            "\n",
            "--- Config: Act=relu, Init=xavier, Optim=rmsprop ---\n",
            "Epoch [1/10], Loss: 0.9960, Acc: 63.53%\n",
            "Epoch [2/10], Loss: 0.5429, Acc: 72.44%\n",
            "Epoch [3/10], Loss: 0.4741, Acc: 77.51%\n",
            "Epoch [4/10], Loss: 0.4321, Acc: 80.43%\n",
            "Epoch [5/10], Loss: 0.3986, Acc: 82.14%\n",
            "Epoch [6/10], Loss: 0.3712, Acc: 83.62%\n",
            "Epoch [7/10], Loss: 0.3529, Acc: 84.95%\n",
            "Epoch [8/10], Loss: 0.3332, Acc: 85.89%\n",
            "Epoch [9/10], Loss: 0.3079, Acc: 87.05%\n",
            "Epoch [10/10], Loss: 0.2990, Acc: 87.42%\n",
            "Test Accuracy: 70.42%\n",
            "\n",
            "--- Config: Act=relu, Init=kaiming, Optim=sgd ---\n",
            "Epoch [1/10], Loss: 0.6278, Acc: 66.44%\n",
            "Epoch [2/10], Loss: 0.5407, Acc: 72.33%\n",
            "Epoch [3/10], Loss: 0.5073, Acc: 74.68%\n",
            "Epoch [4/10], Loss: 0.4804, Acc: 76.77%\n",
            "Epoch [5/10], Loss: 0.4598, Acc: 78.43%\n",
            "Epoch [6/10], Loss: 0.4463, Acc: 78.92%\n",
            "Epoch [7/10], Loss: 0.4294, Acc: 80.05%\n",
            "Epoch [8/10], Loss: 0.4168, Acc: 80.70%\n",
            "Epoch [9/10], Loss: 0.4021, Acc: 81.90%\n",
            "Epoch [10/10], Loss: 0.3959, Acc: 82.07%\n",
            "Test Accuracy: 81.89%\n",
            "\n",
            "--- Config: Act=relu, Init=kaiming, Optim=adam ---\n",
            "Epoch [1/10], Loss: 0.6462, Acc: 67.62%\n",
            "Epoch [2/10], Loss: 0.4955, Acc: 76.24%\n",
            "Epoch [3/10], Loss: 0.4394, Acc: 80.06%\n",
            "Epoch [4/10], Loss: 0.4044, Acc: 82.16%\n",
            "Epoch [5/10], Loss: 0.3764, Acc: 83.55%\n",
            "Epoch [6/10], Loss: 0.3644, Acc: 84.39%\n",
            "Epoch [7/10], Loss: 0.3369, Acc: 85.78%\n",
            "Epoch [8/10], Loss: 0.3184, Acc: 86.43%\n",
            "Epoch [9/10], Loss: 0.3050, Acc: 87.32%\n",
            "Epoch [10/10], Loss: 0.2903, Acc: 87.86%\n",
            "Test Accuracy: 87.08%\n",
            "\n",
            "--- Config: Act=relu, Init=kaiming, Optim=rmsprop ---\n",
            "Epoch [1/10], Loss: 0.9811, Acc: 64.12%\n",
            "Epoch [2/10], Loss: 0.5305, Acc: 73.64%\n",
            "Epoch [3/10], Loss: 0.4696, Acc: 78.21%\n",
            "Epoch [4/10], Loss: 0.4254, Acc: 80.89%\n",
            "Epoch [5/10], Loss: 0.3953, Acc: 82.78%\n",
            "Epoch [6/10], Loss: 0.3718, Acc: 83.77%\n",
            "Epoch [7/10], Loss: 0.3480, Acc: 84.92%\n",
            "Epoch [8/10], Loss: 0.3296, Acc: 85.97%\n",
            "Epoch [9/10], Loss: 0.3135, Acc: 86.69%\n",
            "Epoch [10/10], Loss: 0.2961, Acc: 87.52%\n",
            "Test Accuracy: 87.44%\n",
            "\n",
            "--- Config: Act=relu, Init=random, Optim=sgd ---\n",
            "Epoch [1/10], Loss: 0.5895, Acc: 68.12%\n",
            "Epoch [2/10], Loss: 0.5081, Acc: 74.89%\n",
            "Epoch [3/10], Loss: 0.4705, Acc: 77.65%\n",
            "Epoch [4/10], Loss: 0.4378, Acc: 79.95%\n",
            "Epoch [5/10], Loss: 0.4129, Acc: 81.03%\n",
            "Epoch [6/10], Loss: 0.3988, Acc: 81.97%\n",
            "Epoch [7/10], Loss: 0.3817, Acc: 82.99%\n",
            "Epoch [8/10], Loss: 0.3728, Acc: 83.32%\n",
            "Epoch [9/10], Loss: 0.3576, Acc: 84.00%\n",
            "Epoch [10/10], Loss: 0.3441, Acc: 84.82%\n",
            "Test Accuracy: 83.74%\n",
            "\n",
            "--- Config: Act=relu, Init=random, Optim=adam ---\n",
            "Epoch [1/10], Loss: 0.6060, Acc: 67.00%\n",
            "Epoch [2/10], Loss: 0.5229, Acc: 74.23%\n",
            "Epoch [3/10], Loss: 0.4736, Acc: 77.62%\n",
            "Epoch [4/10], Loss: 0.4350, Acc: 80.11%\n",
            "Epoch [5/10], Loss: 0.4015, Acc: 81.88%\n",
            "Epoch [6/10], Loss: 0.3804, Acc: 83.49%\n",
            "Epoch [7/10], Loss: 0.3586, Acc: 84.44%\n",
            "Epoch [8/10], Loss: 0.3312, Acc: 85.65%\n",
            "Epoch [9/10], Loss: 0.3156, Acc: 86.75%\n",
            "Epoch [10/10], Loss: 0.3040, Acc: 87.17%\n",
            "Test Accuracy: 84.86%\n",
            "\n",
            "--- Config: Act=relu, Init=random, Optim=rmsprop ---\n",
            "Epoch [1/10], Loss: 0.7460, Acc: 64.09%\n",
            "Epoch [2/10], Loss: 0.5309, Acc: 73.33%\n",
            "Epoch [3/10], Loss: 0.4764, Acc: 77.67%\n",
            "Epoch [4/10], Loss: 0.4359, Acc: 80.02%\n",
            "Epoch [5/10], Loss: 0.4048, Acc: 81.81%\n",
            "Epoch [6/10], Loss: 0.3814, Acc: 83.14%\n",
            "Epoch [7/10], Loss: 0.3589, Acc: 84.31%\n",
            "Epoch [8/10], Loss: 0.3388, Acc: 85.42%\n",
            "Epoch [9/10], Loss: 0.3199, Acc: 86.38%\n",
            "Epoch [10/10], Loss: 0.3005, Acc: 86.96%\n",
            "Test Accuracy: 87.76%\n",
            "\n",
            "--- Config: Act=tanh, Init=xavier, Optim=sgd ---\n",
            "Epoch [1/10], Loss: 0.6812, Acc: 62.35%\n",
            "Epoch [2/10], Loss: 0.5897, Acc: 68.21%\n",
            "Epoch [3/10], Loss: 0.5592, Acc: 70.48%\n",
            "Epoch [4/10], Loss: 0.5377, Acc: 72.43%\n",
            "Epoch [5/10], Loss: 0.5186, Acc: 74.21%\n",
            "Epoch [6/10], Loss: 0.5086, Acc: 74.82%\n",
            "Epoch [7/10], Loss: 0.4967, Acc: 75.79%\n",
            "Epoch [8/10], Loss: 0.4855, Acc: 76.62%\n",
            "Epoch [9/10], Loss: 0.4728, Acc: 77.03%\n",
            "Epoch [10/10], Loss: 0.4662, Acc: 77.71%\n",
            "Test Accuracy: 76.75%\n",
            "\n",
            "--- Config: Act=tanh, Init=xavier, Optim=adam ---\n",
            "Epoch [1/10], Loss: 0.7291, Acc: 63.30%\n",
            "Epoch [2/10], Loss: 0.5786, Acc: 69.40%\n",
            "Epoch [3/10], Loss: 0.5560, Acc: 71.13%\n",
            "Epoch [4/10], Loss: 0.5393, Acc: 72.61%\n",
            "Epoch [5/10], Loss: 0.5186, Acc: 74.12%\n",
            "Epoch [6/10], Loss: 0.5028, Acc: 75.50%\n",
            "Epoch [7/10], Loss: 0.4929, Acc: 76.22%\n",
            "Epoch [8/10], Loss: 0.4754, Acc: 77.20%\n",
            "Epoch [9/10], Loss: 0.4592, Acc: 78.48%\n",
            "Epoch [10/10], Loss: 0.4426, Acc: 79.42%\n",
            "Test Accuracy: 79.47%\n",
            "\n",
            "--- Config: Act=tanh, Init=xavier, Optim=rmsprop ---\n",
            "Epoch [1/10], Loss: 0.7471, Acc: 60.64%\n",
            "Epoch [2/10], Loss: 0.6011, Acc: 67.29%\n",
            "Epoch [3/10], Loss: 0.5753, Acc: 69.83%\n",
            "Epoch [4/10], Loss: 0.5509, Acc: 71.94%\n",
            "Epoch [5/10], Loss: 0.5333, Acc: 73.08%\n",
            "Epoch [6/10], Loss: 0.5160, Acc: 74.62%\n",
            "Epoch [7/10], Loss: 0.5031, Acc: 75.51%\n",
            "Epoch [8/10], Loss: 0.4862, Acc: 76.45%\n",
            "Epoch [9/10], Loss: 0.4751, Acc: 77.38%\n",
            "Epoch [10/10], Loss: 0.4586, Acc: 78.35%\n",
            "Test Accuracy: 79.09%\n",
            "\n",
            "--- Config: Act=tanh, Init=kaiming, Optim=sgd ---\n",
            "Epoch [1/10], Loss: 0.6728, Acc: 62.77%\n",
            "Epoch [2/10], Loss: 0.5803, Acc: 69.07%\n",
            "Epoch [3/10], Loss: 0.5508, Acc: 71.54%\n",
            "Epoch [4/10], Loss: 0.5323, Acc: 72.62%\n",
            "Epoch [5/10], Loss: 0.5136, Acc: 74.45%\n",
            "Epoch [6/10], Loss: 0.4999, Acc: 75.27%\n",
            "Epoch [7/10], Loss: 0.4920, Acc: 76.05%\n",
            "Epoch [8/10], Loss: 0.4801, Acc: 76.89%\n",
            "Epoch [9/10], Loss: 0.4723, Acc: 77.34%\n",
            "Epoch [10/10], Loss: 0.4581, Acc: 78.30%\n",
            "Test Accuracy: 78.07%\n",
            "\n",
            "--- Config: Act=tanh, Init=kaiming, Optim=adam ---\n",
            "Epoch [1/10], Loss: 0.7065, Acc: 64.46%\n",
            "Epoch [2/10], Loss: 0.5662, Acc: 70.41%\n",
            "Epoch [3/10], Loss: 0.5343, Acc: 72.87%\n",
            "Epoch [4/10], Loss: 0.5114, Acc: 74.75%\n",
            "Epoch [5/10], Loss: 0.4912, Acc: 76.08%\n",
            "Epoch [6/10], Loss: 0.4678, Acc: 77.63%\n",
            "Epoch [7/10], Loss: 0.4531, Acc: 78.84%\n",
            "Epoch [8/10], Loss: 0.4306, Acc: 80.26%\n",
            "Epoch [9/10], Loss: 0.4125, Acc: 80.99%\n",
            "Epoch [10/10], Loss: 0.4068, Acc: 81.40%\n",
            "Test Accuracy: 80.95%\n",
            "\n",
            "--- Config: Act=tanh, Init=kaiming, Optim=rmsprop ---\n",
            "Epoch [1/10], Loss: 0.7372, Acc: 62.12%\n",
            "Epoch [2/10], Loss: 0.5892, Acc: 68.63%\n",
            "Epoch [3/10], Loss: 0.5529, Acc: 71.78%\n",
            "Epoch [4/10], Loss: 0.5261, Acc: 73.87%\n",
            "Epoch [5/10], Loss: 0.5067, Acc: 75.16%\n",
            "Epoch [6/10], Loss: 0.4923, Acc: 75.86%\n",
            "Epoch [7/10], Loss: 0.4773, Acc: 77.06%\n",
            "Epoch [8/10], Loss: 0.4572, Acc: 78.34%\n",
            "Epoch [9/10], Loss: 0.4418, Acc: 79.38%\n",
            "Epoch [10/10], Loss: 0.4255, Acc: 80.26%\n",
            "Test Accuracy: 80.65%\n",
            "\n",
            "--- Config: Act=tanh, Init=random, Optim=sgd ---\n",
            "Epoch [1/10], Loss: 0.6324, Acc: 63.38%\n",
            "Epoch [2/10], Loss: 0.5952, Acc: 67.44%\n",
            "Epoch [3/10], Loss: 0.5691, Acc: 69.81%\n",
            "Epoch [4/10], Loss: 0.5495, Acc: 71.31%\n",
            "Epoch [5/10], Loss: 0.5303, Acc: 73.02%\n",
            "Epoch [6/10], Loss: 0.5160, Acc: 74.31%\n",
            "Epoch [7/10], Loss: 0.4944, Acc: 75.62%\n",
            "Epoch [8/10], Loss: 0.4810, Acc: 76.61%\n",
            "Epoch [9/10], Loss: 0.4701, Acc: 77.44%\n",
            "Epoch [10/10], Loss: 0.4571, Acc: 78.33%\n",
            "Test Accuracy: 79.01%\n",
            "\n",
            "--- Config: Act=tanh, Init=random, Optim=adam ---\n",
            "Epoch [1/10], Loss: 0.6474, Acc: 62.75%\n",
            "Epoch [2/10], Loss: 0.5907, Acc: 68.00%\n",
            "Epoch [3/10], Loss: 0.5689, Acc: 70.02%\n",
            "Epoch [4/10], Loss: 0.5524, Acc: 71.42%\n",
            "Epoch [5/10], Loss: 0.5331, Acc: 72.93%\n",
            "Epoch [6/10], Loss: 0.5200, Acc: 74.24%\n",
            "Epoch [7/10], Loss: 0.5061, Acc: 75.14%\n",
            "Epoch [8/10], Loss: 0.4932, Acc: 76.45%\n",
            "Epoch [9/10], Loss: 0.4847, Acc: 76.63%\n",
            "Epoch [10/10], Loss: 0.4657, Acc: 77.74%\n",
            "Test Accuracy: 77.65%\n",
            "\n",
            "--- Config: Act=tanh, Init=random, Optim=rmsprop ---\n",
            "Epoch [1/10], Loss: 0.6837, Acc: 59.79%\n",
            "Epoch [2/10], Loss: 0.6052, Acc: 66.98%\n",
            "Epoch [3/10], Loss: 0.5851, Acc: 69.28%\n",
            "Epoch [4/10], Loss: 0.5703, Acc: 69.90%\n",
            "Epoch [5/10], Loss: 0.5534, Acc: 71.71%\n",
            "Epoch [6/10], Loss: 0.5480, Acc: 71.90%\n",
            "Epoch [7/10], Loss: 0.5293, Acc: 73.43%\n",
            "Epoch [8/10], Loss: 0.5217, Acc: 74.30%\n",
            "Epoch [9/10], Loss: 0.5112, Acc: 74.82%\n",
            "Epoch [10/10], Loss: 0.4962, Acc: 76.00%\n",
            "Test Accuracy: 74.28%\n",
            "\n",
            "--- Config: Act=leaky_relu, Init=xavier, Optim=sgd ---\n",
            "Epoch [1/10], Loss: 0.6116, Acc: 67.59%\n",
            "Epoch [2/10], Loss: 0.5191, Acc: 74.18%\n",
            "Epoch [3/10], Loss: 0.4832, Acc: 76.83%\n",
            "Epoch [4/10], Loss: 0.4567, Acc: 78.56%\n",
            "Epoch [5/10], Loss: 0.4351, Acc: 79.90%\n",
            "Epoch [6/10], Loss: 0.4177, Acc: 80.88%\n",
            "Epoch [7/10], Loss: 0.4019, Acc: 81.66%\n",
            "Epoch [8/10], Loss: 0.3840, Acc: 82.86%\n",
            "Epoch [9/10], Loss: 0.3764, Acc: 83.09%\n",
            "Epoch [10/10], Loss: 0.3698, Acc: 83.66%\n",
            "Test Accuracy: 82.78%\n",
            "\n",
            "--- Config: Act=leaky_relu, Init=xavier, Optim=adam ---\n",
            "Epoch [1/10], Loss: 0.6476, Acc: 66.31%\n",
            "Epoch [2/10], Loss: 0.5191, Acc: 74.51%\n",
            "Epoch [3/10], Loss: 0.4666, Acc: 78.16%\n",
            "Epoch [4/10], Loss: 0.4256, Acc: 80.51%\n",
            "Epoch [5/10], Loss: 0.3931, Acc: 82.76%\n",
            "Epoch [6/10], Loss: 0.3629, Acc: 83.88%\n",
            "Epoch [7/10], Loss: 0.3472, Acc: 85.06%\n",
            "Epoch [8/10], Loss: 0.3182, Acc: 86.51%\n",
            "Epoch [9/10], Loss: 0.3024, Acc: 87.01%\n",
            "Epoch [10/10], Loss: 0.2855, Acc: 88.10%\n",
            "Test Accuracy: 87.76%\n",
            "\n",
            "--- Config: Act=leaky_relu, Init=xavier, Optim=rmsprop ---\n",
            "Epoch [1/10], Loss: 0.9813, Acc: 61.21%\n",
            "Epoch [2/10], Loss: 0.5780, Acc: 70.52%\n",
            "Epoch [3/10], Loss: 0.5028, Acc: 75.84%\n",
            "Epoch [4/10], Loss: 0.4424, Acc: 79.38%\n",
            "Epoch [5/10], Loss: 0.4073, Acc: 81.57%\n",
            "Epoch [6/10], Loss: 0.3763, Acc: 83.32%\n",
            "Epoch [7/10], Loss: 0.3446, Acc: 85.06%\n",
            "Epoch [8/10], Loss: 0.3242, Acc: 85.84%\n",
            "Epoch [9/10], Loss: 0.2982, Acc: 87.23%\n",
            "Epoch [10/10], Loss: 0.2755, Acc: 88.38%\n",
            "Test Accuracy: 88.02%\n",
            "\n",
            "--- Config: Act=leaky_relu, Init=kaiming, Optim=sgd ---\n",
            "Epoch [1/10], Loss: 0.6286, Acc: 66.49%\n",
            "Epoch [2/10], Loss: 0.5368, Acc: 72.86%\n",
            "Epoch [3/10], Loss: 0.5001, Acc: 75.63%\n",
            "Epoch [4/10], Loss: 0.4776, Acc: 77.29%\n",
            "Epoch [5/10], Loss: 0.4561, Acc: 78.19%\n",
            "Epoch [6/10], Loss: 0.4395, Acc: 79.12%\n",
            "Epoch [7/10], Loss: 0.4244, Acc: 80.44%\n",
            "Epoch [8/10], Loss: 0.4190, Acc: 80.75%\n",
            "Epoch [9/10], Loss: 0.4032, Acc: 81.68%\n",
            "Epoch [10/10], Loss: 0.3908, Acc: 82.42%\n",
            "Test Accuracy: 81.89%\n",
            "\n",
            "--- Config: Act=leaky_relu, Init=kaiming, Optim=adam ---\n",
            "Epoch [1/10], Loss: 0.6427, Acc: 66.81%\n",
            "Epoch [2/10], Loss: 0.5034, Acc: 75.51%\n",
            "Epoch [3/10], Loss: 0.4429, Acc: 79.63%\n",
            "Epoch [4/10], Loss: 0.4046, Acc: 81.87%\n",
            "Epoch [5/10], Loss: 0.3752, Acc: 83.59%\n",
            "Epoch [6/10], Loss: 0.3540, Acc: 85.04%\n",
            "Epoch [7/10], Loss: 0.3325, Acc: 85.93%\n",
            "Epoch [8/10], Loss: 0.3081, Acc: 86.84%\n",
            "Epoch [9/10], Loss: 0.2902, Acc: 87.79%\n",
            "Epoch [10/10], Loss: 0.2715, Acc: 88.68%\n",
            "Test Accuracy: 88.66%\n",
            "\n",
            "--- Config: Act=leaky_relu, Init=kaiming, Optim=rmsprop ---\n",
            "Epoch [1/10], Loss: 0.8630, Acc: 64.20%\n",
            "Epoch [2/10], Loss: 0.5424, Acc: 73.25%\n",
            "Epoch [3/10], Loss: 0.4801, Acc: 77.30%\n",
            "Epoch [4/10], Loss: 0.4298, Acc: 80.60%\n",
            "Epoch [5/10], Loss: 0.3956, Acc: 82.34%\n",
            "Epoch [6/10], Loss: 0.3652, Acc: 83.79%\n",
            "Epoch [7/10], Loss: 0.3417, Acc: 85.37%\n",
            "Epoch [8/10], Loss: 0.3158, Acc: 86.25%\n",
            "Epoch [9/10], Loss: 0.2949, Acc: 87.57%\n",
            "Epoch [10/10], Loss: 0.2747, Acc: 88.18%\n",
            "Test Accuracy: 84.02%\n",
            "\n",
            "--- Config: Act=leaky_relu, Init=random, Optim=sgd ---\n",
            "Epoch [1/10], Loss: 0.5962, Acc: 67.68%\n",
            "Epoch [2/10], Loss: 0.5140, Acc: 74.80%\n",
            "Epoch [3/10], Loss: 0.4659, Acc: 78.06%\n",
            "Epoch [4/10], Loss: 0.4322, Acc: 79.97%\n",
            "Epoch [5/10], Loss: 0.4141, Acc: 81.12%\n",
            "Epoch [6/10], Loss: 0.3955, Acc: 82.42%\n",
            "Epoch [7/10], Loss: 0.3762, Acc: 83.10%\n",
            "Epoch [8/10], Loss: 0.3685, Acc: 83.64%\n",
            "Epoch [9/10], Loss: 0.3608, Acc: 84.19%\n",
            "Epoch [10/10], Loss: 0.3474, Acc: 84.77%\n",
            "Test Accuracy: 82.38%\n",
            "\n",
            "--- Config: Act=leaky_relu, Init=random, Optim=adam ---\n",
            "Epoch [1/10], Loss: 0.6227, Acc: 65.59%\n",
            "Epoch [2/10], Loss: 0.5432, Acc: 72.45%\n",
            "Epoch [3/10], Loss: 0.4992, Acc: 75.75%\n",
            "Epoch [4/10], Loss: 0.4575, Acc: 78.50%\n",
            "Epoch [5/10], Loss: 0.4254, Acc: 80.77%\n",
            "Epoch [6/10], Loss: 0.4046, Acc: 81.73%\n",
            "Epoch [7/10], Loss: 0.3741, Acc: 83.64%\n",
            "Epoch [8/10], Loss: 0.3483, Acc: 84.74%\n",
            "Epoch [9/10], Loss: 0.3321, Acc: 85.53%\n",
            "Epoch [10/10], Loss: 0.3071, Acc: 86.65%\n",
            "Test Accuracy: 79.39%\n",
            "\n",
            "--- Config: Act=leaky_relu, Init=random, Optim=rmsprop ---\n",
            "Epoch [1/10], Loss: 0.7596, Acc: 62.56%\n",
            "Epoch [2/10], Loss: 0.5635, Acc: 70.99%\n",
            "Epoch [3/10], Loss: 0.5133, Acc: 74.79%\n",
            "Epoch [4/10], Loss: 0.4614, Acc: 78.73%\n",
            "Epoch [5/10], Loss: 0.4244, Acc: 80.80%\n",
            "Epoch [6/10], Loss: 0.3897, Acc: 82.68%\n",
            "Epoch [7/10], Loss: 0.3590, Acc: 84.22%\n",
            "Epoch [8/10], Loss: 0.3334, Acc: 85.28%\n",
            "Epoch [9/10], Loss: 0.3101, Acc: 86.62%\n",
            "Epoch [10/10], Loss: 0.2890, Acc: 87.41%\n",
            "Test Accuracy: 79.83%\n",
            "\n",
            "Best Custom Configuration: {'act': 'leaky_relu', 'init': 'kaiming', 'opt': 'adam'} with Acc: 88.66%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RESNET-18 TRANSFER LEARNING\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# -------- DEVICE --------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# -------- TRANSFORMS (ImageNet) --------\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# -------- DATASET --------\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root=\"/content/cats_dogs/train\",\n",
        "    transform=transform_train\n",
        ")\n",
        "\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    root=\"/content/cats_dogs/val\",\n",
        "    transform=transform_test\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=32,\n",
        "    shuffle=True, num_workers=2, pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=32,\n",
        "    shuffle=False, num_workers=2, pin_memory=True\n",
        ")\n",
        "\n",
        "print(\"Classes:\", train_dataset.classes)\n",
        "\n",
        "# -------- MODEL --------\n",
        "print(\"\\n--- Starting Transfer Learning (ResNet-18 | Cats vs Dogs) ---\")\n",
        "\n",
        "resnet = models.resnet18(\n",
        "    weights=models.ResNet18_Weights.IMAGENET1K_V1\n",
        ")\n",
        "\n",
        "# Freeze backbone\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace FC layer\n",
        "num_ftrs = resnet.fc.in_features\n",
        "resnet.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "resnet = resnet.to(device)\n",
        "\n",
        "# -------- TRAINING --------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet.fc.parameters(), lr=0.001)\n",
        "\n",
        "train_model(\n",
        "    resnet,\n",
        "    train_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "# -------- EVALUATION --------\n",
        "resnet_acc = evaluate_model(resnet, test_loader)\n",
        "\n",
        "print(f\"\\nResNet-18 Accuracy (Cats vs Dogs): {resnet_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmUO9hR0CSXm",
        "outputId": "c513adab-e400-45eb-fd31-53bfc1689659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Classes: ['cat', 'dog']\n",
            "\n",
            "--- Starting Transfer Learning (ResNet-18 | Cats vs Dogs) ---\n",
            "Epoch [1/20], Loss: 0.1219, Acc: 95.37%\n",
            "Epoch [2/20], Loss: 0.0860, Acc: 96.70%\n",
            "Epoch [3/20], Loss: 0.0769, Acc: 96.95%\n",
            "Epoch [4/20], Loss: 0.0756, Acc: 97.04%\n",
            "Epoch [5/20], Loss: 0.0717, Acc: 97.26%\n",
            "Epoch [6/20], Loss: 0.0757, Acc: 97.00%\n",
            "Epoch [7/20], Loss: 0.0745, Acc: 97.18%\n",
            "Epoch [8/20], Loss: 0.0688, Acc: 97.39%\n",
            "Epoch [9/20], Loss: 0.0670, Acc: 97.40%\n",
            "Epoch [10/20], Loss: 0.0697, Acc: 97.30%\n",
            "Epoch [11/20], Loss: 0.0700, Acc: 97.23%\n",
            "Epoch [12/20], Loss: 0.0736, Acc: 97.17%\n",
            "Epoch [13/20], Loss: 0.0673, Acc: 97.34%\n",
            "Epoch [14/20], Loss: 0.0686, Acc: 97.32%\n",
            "Epoch [15/20], Loss: 0.0631, Acc: 97.59%\n",
            "Epoch [16/20], Loss: 0.0694, Acc: 97.43%\n",
            "Epoch [17/20], Loss: 0.0697, Acc: 97.35%\n",
            "Epoch [18/20], Loss: 0.0722, Acc: 97.18%\n",
            "Epoch [19/20], Loss: 0.0654, Acc: 97.54%\n",
            "Epoch [20/20], Loss: 0.0710, Acc: 97.26%\n",
            "\n",
            "ResNet-18 Accuracy (Cats vs Dogs): 98.10%\n"
          ]
        }
      ]
    }
  ]
}